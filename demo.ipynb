{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFDQNXs8oeIQ"
      },
      "source": [
        "Imports NLTK and Regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j92eDuW_oXeo",
        "outputId": "1d09112f-bbad-47c6-ac0b-42df707a6bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.corpus import brown #brown dataset required\n",
        "from nltk.stem import PorterStemmer\n",
        "import regex\n",
        "import copy\n",
        "import numpy as np\n",
        "nltk.download(\"brown\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1PEm7UKofoL"
      },
      "source": [
        "Preprocess steps like tokenization and normalization function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofPwj2QJoag_"
      },
      "outputs": [],
      "source": [
        "def process_sentence(sentence):\n",
        "  stemmer = PorterStemmer()\n",
        "  new_sentence = [\"<S>\",\"<S>\"]\n",
        "  stem_sentence = [stemmer.stem(word) for word in sentence] #Stem words\n",
        "  #for word in sentence:\n",
        "  for word in stem_sentence:\n",
        "    word_span = regex.match(\"([[:punct:]])*\",word).span() #remove punctuation\n",
        "    if(word_span[0] == 0 and word_span[1] == len(word)): #If the 'word' is punctuation, dont add it to processed_sentences\n",
        "      continue\n",
        "    new_sentence.append(word.lower())\n",
        "  new_sentence.append(\"<E>\")\n",
        "  return new_sentence\n",
        "\n",
        "def preprocess_data(sentences):#Given a list of [(topic,[sentence])], it returns two dicts, one of vocab set and one of processed&tokenized sentences with key being genre\n",
        "  # TODO: Add preprocessing steps (tokenization, normalization, etc.)\n",
        "  processed_sentences = defaultdict(lambda:[])\n",
        "  vocab = defaultdict(lambda:{\"<S>\",\"<E>\"})\n",
        "  for topic_sentence in sentences:\n",
        "    sentence = topic_sentence[1]\n",
        "    new_sentence = process_sentence(sentence)\n",
        "    for word in new_sentence:\n",
        "      vocab[topic_sentence[0]].add(word.lower())\n",
        "    processed_sentences[topic_sentence[0]].append(new_sentence)\n",
        "  return processed_sentences, vocab\n",
        "\n",
        "def convert_fid_to_genre(fid_sentences,output='dict'):#Given a dict of FID:Sentences, it converts it to either a dict or list of genre to sentences\n",
        "  fid_to_genre= {\"a\":\"news\",\n",
        "                 \"b\":\"editorial\",\n",
        "                 \"c\":\"reviews\",\n",
        "                 \"d\":\"religion\",\n",
        "                 \"e\":\"hobbies\",\n",
        "                 \"f\":\"lore\",\n",
        "                 \"g\":\"belles_lettres\",\n",
        "                 \"h\":\"government\",\n",
        "                 \"j\":\"learned\",\n",
        "                 \"k\":\"fiction\",\n",
        "                 \"l\":\"mystery\",\n",
        "                 \"m\":\"science_fiction\",\n",
        "                 \"n\":\"adventure\",\n",
        "                 \"p\":\"romance\",\n",
        "                 \"r\":\"humor\"\n",
        "                 }\n",
        "  if(output=='dict'):\n",
        "    genre_sentences=defaultdict(lambda:[])\n",
        "    for key in fid_sentences:\n",
        "      genre_sentences[fid_to_genre[key[1]]]+=fid_sentences[key]\n",
        "    return genre_sentences\n",
        "  else:#make a list of tuples, where the first value is the key and the second is the sentence\n",
        "    genre_sentences=[]\n",
        "    for key in fid_sentences.keys():\n",
        "      for sentence in fid_sentences[key]:\n",
        "        genre_sentences.append((fid_to_genre[key[1]],sentence))\n",
        "    return genre_sentences\n",
        "\n",
        "def get_sentences_with_fids(corpus=brown,start=32000,end=42000): #Get sentences in given subset and returns them in a dictionary with correlating FID\n",
        "  fid_sentences = {}\n",
        "  count = 0\n",
        "  sentences = set(tuple(row) for row in brown.sents()[start:end])\n",
        "  sentences_list = [row for row in brown.sents()[start:end]]\n",
        "  fidCounter = -1\n",
        "  found = -1\n",
        "  for fid in corpus.fileids():\n",
        "    fidCounter+=1\n",
        "    sent = [row for row in corpus.sents(fileids=fid)]\n",
        "    #genre_sentences[cat] = defaultdict(lambda:0)\n",
        "    sent_tuple = set(tuple(row) for row in sent)\n",
        "\n",
        "\n",
        "    if(sent_tuple.issubset(sentences)):\n",
        "      if(count==0 and sent!=sentences_list[:len(sent)]):#The first FID will more than likely not start at our start length\n",
        "        for i in range(0,end-start-len(sent)):\n",
        "          for j in range(0,len(sent)):\n",
        "            if(sent[j]!=sentences_list[j+i]):\n",
        "              break\n",
        "            if(j==len(sent)-1):\n",
        "              found=i\n",
        "          if(found>-1):\n",
        "            found = i\n",
        "            break\n",
        "        if(found<0):\n",
        "          print(\"ERROR in get_sentences_with_fid1, set not found\")\n",
        "          return None\n",
        "        count+=found\n",
        "      fid_sentences[fid] = sent\n",
        "      count+=len(sent)\n",
        "\n",
        "  if(found>-1 or count<(end-start-1)):\n",
        "    first_fid = set(tuple(row) for row in sentences_list[:found])\n",
        "    last_fid = set(tuple(row) for row in sentences_list[count:])\n",
        "    for fid in corpus.fileids():\n",
        "      if(found==-1 and count>(end-start-1)):\n",
        "        break\n",
        "      if fid in fid_sentences.keys():\n",
        "        continue\n",
        "      sent = corpus.sents(fileids=fid)\n",
        "      sent_tuple = set(tuple(row) for row in sent)\n",
        "      if(first_fid.issubset(sent_tuple)):\n",
        "        fid_sentences[fid] = sentences_list[:found]\n",
        "        found = -1\n",
        "      if(last_fid.issubset(sent_tuple)):\n",
        "        fid_sentences[fid] = sentences_list[count:]\n",
        "        count+=len(sentences_list[count:])\n",
        "    # for i in range(0,len(sent)):\n",
        "    #   while(sent[i] in sentences and i<len(sent)):\n",
        "    #     fid_sentences[fid].append(sent[i])\n",
        "    #     i+=1\n",
        "  #print(fid_sentences)\n",
        "\n",
        "  return fid_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. PRESS: REPORTAGE\n",
        "B. PRESS: EDITORIAL\n",
        "C. PRESS: REVIEWS\n",
        "D. RELIGION\n",
        "E. SKILL AND HOBBIES\n",
        "F. POPULAR LORE\n",
        "G. BELLES-LETTRES\n",
        "H. MISCELLANEOUS: GOVERNMENT & HOUSE ORGANS\n",
        "J. LEARNED\n",
        "K: FICTION: GENERAL\n",
        "L: FICTION: MYSTERY\n",
        "M: FICTION: SCIENCE\n",
        "N: FICTION: ADVENTURE\n",
        "P. FICTION: ROMANCE\n",
        "R. HUMOR\n"
      ],
      "metadata": {
        "id": "N2ZiJ3N5JRPH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSo0njZio6h9"
      },
      "source": [
        "Prepare and download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgLw11OCpAjh",
        "outputId": "fe9f66ba-1b75-441e-bfa6-6571bfcae2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learned 6136\n",
            "fiction 3864\n",
            "10000\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "#print(brown.sents()[1].categories())\n",
        "fid = get_sentences_with_fids()\n",
        "#cat = convert_fid_to_genre(fid,output='dict')\n",
        "sentences = convert_fid_to_genre(fid,output='list')\n",
        "# print(len(sentences))\n",
        "#print(genre_sentences(sentences))\n",
        "#print(sentences[6432])\n",
        "#print(len(sentences))\n",
        "processed_sentences,vocab = preprocess_data(sentences)\n",
        "\n",
        "tot=0\n",
        "for k in processed_sentences.keys():\n",
        "    tot+=len(processed_sentences[k])\n",
        "    print(k,len(processed_sentences[k]))\n",
        "print(tot)\n",
        "#print(processed_sentences[6432])\n",
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx05J8RKo6pd"
      },
      "source": [
        "Initialize Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLNt-IuOpMMR"
      },
      "outputs": [],
      "source": [
        "#alpha = 1\n",
        "prob_model = defaultdict(lambda:defaultdict(lambda: defaultdict(lambda: 0))) #topic->w1w2->w3\n",
        "laplace_model = defaultdict(lambda:defaultdict(lambda: defaultdict(lambda: 0))) #topic->w1w2->w3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x567kFKxo6wE"
      },
      "source": [
        "Build a Trigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM2wKCBCpS3V"
      },
      "outputs": [],
      "source": [
        "for topic in processed_sentences:\n",
        "  for sentence in processed_sentences[topic]:\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=False, pad_left=False):\n",
        "      prob_model[topic][(w1, w2)][w3] += 1\n",
        "      laplace_model[topic][(w1, w2)][w3] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1-myatYo62j"
      },
      "source": [
        "Transform the counts to probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx25Fdv7pcYk"
      },
      "outputs": [],
      "source": [
        "#prob_model = copy.deepcopy(model)\n",
        "for topic in prob_model:\n",
        "  for w1_w2 in prob_model[topic]:\n",
        "    total_count = float(sum(prob_model[topic][w1_w2].values()))\n",
        "    for w3 in prob_model[topic][w1_w2]:\n",
        "      prob_model[topic][w1_w2][w3] /= total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q0hE0QQpi7i"
      },
      "source": [
        "Implement Laplace Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3xMypT1pnzU",
        "outputId": "9cfc5fbb-06c2-41bd-ddc5-516fc9f6334d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<E>\n",
            "which\n",
            "-38.29655382384566\n",
            "-38.404578928087375\n"
          ]
        }
      ],
      "source": [
        "#laplace_model = copy.deepcopy(model)\n",
        "class TrigramLaplaceSmoothing:\n",
        "  def __init__(self, vocab,sentences=None,model=None, alpha = 1):\n",
        "    self.alpha = alpha\n",
        "    self.vocab = vocab\n",
        "    if(sentences==None and model==None):\n",
        "      print(\"Either Sentences or Model must have a value\")\n",
        "      print(1/0)\n",
        "    elif(sentences==None):\n",
        "      self.model = copy.deepcopy(model)\n",
        "    elif(model==None):\n",
        "      self.sentences=sentences\n",
        "      self.model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "      for sentence in sentences:\n",
        "        for w1, w2, w3 in trigrams(sentence, pad_right=False, pad_left=False):\n",
        "          self.model[(w1, w2)][w3] += 1\n",
        "    else:\n",
        "      self.model = copy.deepcopy(model)\n",
        "      self.sentences=sentences\n",
        "\n",
        "    self.laplace = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "  def add_sentence(self, sentence):#add new sentence during validation, and add new vocab to set\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=False, pad_left=False):\n",
        "      self.model[(w1, w2)][w3] += 1\n",
        "    for word in sentence:\n",
        "      self.vocab.add(word)\n",
        "\n",
        "  def set_model(self,model):#set model\n",
        "    self.model = copy.deepcopy(model)\n",
        "\n",
        "  def set_alpha(self,alpha):#set alpha\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def make_it_smooth(self):#redoes all laplace if required\n",
        "    total_words = len(self.vocab)\n",
        "    for w1_w2 in self.model:\n",
        "      total_count = float(sum(self.model[w1_w2].values()))\n",
        "      for w3 in self.model[w1_w2]:\n",
        "        self.laplace[w1_w2][w3] = (self.model[w1_w2][w3]+self.alpha)/(total_count+self.alpha*total_words)\n",
        "\n",
        "  def stored_probabilty(self, w1, w2, w3):#Gets stored probability if exists.  It's faster, but if alpha changes, then you need to call make_it_smooth first\n",
        "    if(self.laplace[w1,w2][w3]==0):\n",
        "      total_words = len(self.vocab)\n",
        "      total_count = float(sum(self.model[w1,w2].values()))\n",
        "    #return (self.model[w1,w2][w3]+self.alpha)/(total_count+self.alpha*total_words)\n",
        "      self.laplace[w1,w2][w3] = (self.model[w1,w2][w3]+self.alpha)/(total_count+self.alpha*total_words)\n",
        "    return self.laplace[w1,w2][w3]\n",
        "\n",
        "  def probability(self, w1, w2, w3):#Gets laplace smoothed probability, unstored so we don't have to worry about wrong alpha values\n",
        "    total_words = len(self.vocab)\n",
        "    total_count = float(sum(self.model[w1,w2].values()))\n",
        "    return (self.model[w1,w2][w3]+self.alpha)/(total_count+self.alpha*total_words)\n",
        "\n",
        "  def probability_of_sentence(self,sentence):#Finds the probability of the sentence existing\n",
        "    if(type(sentence) is str):\n",
        "      sentence = sentence.split()\n",
        "    if(not type(sentence) is list):\n",
        "      print(\"Type error in class TrigramLaplaceSmoothing function probability_of_sentence\")\n",
        "      print(1/0)\n",
        "    processed_sentence = process_sentence(sentence)\n",
        "    pre_prob = 0\n",
        "    for w1, w2, w3 in trigrams(processed_sentence, pad_right=False, pad_left=False):\n",
        "      pre_prob += np.log(self.probability(w1,w2,w3))#Use logs so we dont have to use small decimals\n",
        "    return pre_prob\n",
        "\n",
        "  def predict_next_word_in_sentence(self,sentence):#Guesses the next word in the sentence\n",
        "    if(type(sentence) is str):\n",
        "      sentence = sentence.split()\n",
        "    if(not type(sentence) is list):\n",
        "      print(\"Type error in class TrigramLaplaceSmoothing function predict_next_word_in_sentence\")\n",
        "      print(1/0)\n",
        "    processed_sentence = process_sentence(sentence)[:-1]\n",
        "    pre_prob = 0\n",
        "    #print(processed_sentence)\n",
        "    for w1, w2, w3 in trigrams(processed_sentence, pad_right=False, pad_left=False):\n",
        "      #print(w1,w2,w3,pre_prob, self.model[w1,w2][w3])\n",
        "      pre_prob += np.log(self.probability(w1,w2,w3))\n",
        "    next_word_dict = {}\n",
        "    #print(pre_prob,processed_sentence[-2],processed_sentence[-1])\n",
        "    for next_word in self.vocab: #any word could be next\n",
        "      next_word_dict[next_word] = pre_prob+np.log(self.probability(processed_sentence[-2],processed_sentence[-1],next_word))\n",
        "\n",
        "    #print(max(next_word_dict,key=next_word_dict.get),next_word_dict[max(next_word_dict,key=next_word_dict.get)])\n",
        "    return max(next_word_dict,key=next_word_dict.get)\n",
        "\n",
        "fiction = TrigramLaplaceSmoothing(model=laplace_model['fiction'],vocab=vocab['fiction'],alpha=1)\n",
        "learned = TrigramLaplaceSmoothing(model=laplace_model['learned'],vocab=vocab['learned'],alpha=1)\n",
        "#test.make_it_smooth()\n",
        "print(fiction.predict_next_word_in_sentence(\"The book\"))\n",
        "print(learned.predict_next_word_in_sentence(\"The book\"))\n",
        "print(fiction.probability_of_sentence(\"The book was complete\"))\n",
        "print(learned.probability_of_sentence(\"The book was complete\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-prI0ZB2pn_D"
      },
      "source": [
        "Predict Next Word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "QHUoVTY6prDM",
        "outputId": "bf34256a-2610-4436-bd05-b5005590c6d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b3aa0c887d58>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaplace_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlaplace_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_next_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fulton'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'County'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-b3aa0c887d58>\u001b[0m in \u001b[0;36mpredict_next_word\u001b[0;34m(w1, w2)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# TODO: Implement the prediction logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Example: return max(model[w1, w2], key=model[w1, w2].get)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaplace_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlaplace_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m#pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_next_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Fulton'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'County'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ],
      "source": [
        "def predict_next_word(w1, w2):\n",
        "  # TODO: Implement the prediction logic\n",
        "  # Example: return max(model[w1, w2], key=model[w1, w2].get)\n",
        "  return max(laplace_model[w1,w2],key=laplace_model[w1,w2].get)\n",
        "  #pass\n",
        "print(predict_next_word('The','Fulton') == 'County')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejf0yEbHptFC"
      },
      "source": [
        "Implement a classifier using the trigram model -- have a simple threshold anything >=0.5 is yes or else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sIZTCi9ps0X"
      },
      "outputs": [],
      "source": [
        "class TrigramClassifier:\n",
        "  def __init__(self, corpus=brown,range=(32000,42000),trn_val_test=(0.6,0.2,0.2),alpha=1):\n",
        "    self.trn_val_test = trn_val_test #Should add up to 1\n",
        "\n",
        "    self.sentences = convert_fid_to_genre(get_sentences_with_fids(corpus,range[0],range[1]),output='list')#The sentences provided by the corpus\n",
        "    np.random.shuffle(self.sentences) #shuffled\n",
        "\n",
        "    #Splits up training, testing, and validation data\n",
        "    trn = self.sentences[:int(len(self.sentences)*trn_val_test[0])]\n",
        "    val = self.sentences[int(len(self.sentences)*trn_val_test[0]):int(-len(self.sentences)*trn_val_test[2])]\n",
        "    test = self.sentences[int(-len(self.sentences)*trn_val_test[2]):]\n",
        "    self.training_sentences,self.training_vocab = preprocess_data(trn)\n",
        "    self.validation_sentences,self.validation_vocab = preprocess_data(val)\n",
        "    self.testing_sentences,self.testing_vocab = preprocess_data(test)\n",
        "\n",
        "    #Classes, global alpha, and whether or not validation is completed\n",
        "    self.alpha = alpha\n",
        "    self.classes = self.training_sentences.keys()\n",
        "    self.validation_complete = False\n",
        "\n",
        "    #Each classifieer in the model\n",
        "    self.classifiers = {}\n",
        "    for c in self.classes:\n",
        "      self.classifiers[c] = TrigramLaplaceSmoothing(sentences = self.training_sentences[c],vocab = self.training_vocab[c])\n",
        "\n",
        "  def print_sorted_dict(self, dict):#prints a guesses sorted\n",
        "    word_list = []\n",
        "    for key in dict:\n",
        "      word_list.append((key,dict[key]))\n",
        "      word_list.sort(key=lambda item:item[1],reverse=True)\n",
        "    for item in word_list:\n",
        "      print(item)\n",
        "\n",
        "  def predict_genres_of_sentence_probabilities(self,sentence):#Returns a dict of each genre and the corresponding prob\n",
        "    if(not(type(sentence) is str or type(sentence) is list)):\n",
        "      print(\"Type invalid in predict_genre_of_sentence; unsuppported type: \"+str(type(sentence)))\n",
        "      print(1/0)\n",
        "\n",
        "    genre_probs = {}\n",
        "    total_sents = 0\n",
        "    total_vocab = set()\n",
        "    for category in self.training_sentences:\n",
        "      total_sents+=len(self.training_sentences[category])\n",
        "      total_vocab.update(self.training_vocab[category])\n",
        "    if(self.validation_complete):#If validation complete, then self.validation is a part of the model vocab and sentences\n",
        "      for category in self.validation_sentences:\n",
        "        total_sents+=len(self.validation_sentences[category])\n",
        "        total_vocab.update(self.validation_vocab[category])\n",
        "\n",
        "    for c in self.classifiers:#I could change the global alpha, but it as 1 has done well\n",
        "      if(self.validation_complete):\n",
        "        genre_probs[c] = self.classifiers[c].probability_of_sentence(sentence) + np.log((len(self.training_sentences[c])+len(self.validation_sentences[c])+self.alpha)/(total_sents+len(total_vocab)*self.alpha))\n",
        "      else:\n",
        "        genre_probs[c] = self.classifiers[c].probability_of_sentence(sentence) + np.log((len(self.training_sentences[c])+self.alpha)/(total_sents+len(total_vocab)*self.alpha))\n",
        "\n",
        "    return genre_probs\n",
        "\n",
        "\n",
        "  def predict_genres_of_sentence(self,sentence):#Returns the classification based off of the highest prob dict\n",
        "    genre_guesses = self.predict_genres_of_sentence_probabilities(sentence)\n",
        "    if(genre_guesses==None):\n",
        "      print(\"predict_genres_of_sentence_probabilities returned no guesses\")\n",
        "      return \"\"\n",
        "    return max(genre_guesses,key=genre_guesses.get)\n",
        "\n",
        "  def test_sentence(self, sentence, genre):#Given a sentence and a genre, returns if the classification is right\n",
        "    if(self.predict_genres_of_sentence(sentence)==genre):\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "\n",
        "  def evaluate(self,level='test'):#Does testing on the testing slice\n",
        "    total = 0\n",
        "    scores = {}\n",
        "    eval_sentences = {}\n",
        "    if(level=='test'):\n",
        "      eval_sentences = self.testing_sentences\n",
        "    elif(level=='val'):\n",
        "      eval_sentences = copy.deepcopy(self.validation_sentences)\n",
        "      for genre in self.training_sentences:\n",
        "        eval_sentences[genre]+=self.training_sentences[genre]\n",
        "    elif(level=='train'):\n",
        "      eval_sentences=self.training_sentences\n",
        "    else:\n",
        "      print(\"Invalid level provided in Class TrigramClassifier method Evaluate\")\n",
        "      print(1/0)\n",
        "\n",
        "    for genre in eval_sentences:\n",
        "      scores[genre] = [0,0,0,0]#TP FN FP TN\n",
        "\n",
        "    for genre in eval_sentences:\n",
        "      for sentence in eval_sentences[genre]:\n",
        "        total+=1\n",
        "        guess = self.predict_genres_of_sentence(sentence)\n",
        "        for g in eval_sentences:\n",
        "          if(g==guess and guess==genre):\n",
        "            scores[g][0]+=1#TP increase\n",
        "          elif(g!=guess and guess==genre):\n",
        "            scores[g][3]+=1#TN increase\n",
        "          elif(g==genre and guess!=genre):\n",
        "            scores[g][1]+=1#FN increase\n",
        "          elif(g==guess and guess!=genre):\n",
        "            scores[g][2]+=1#FP increase\n",
        "          else:\n",
        "            print(g,guess,genre)\n",
        "            print(1/0)\n",
        "    return scores\n",
        "\n",
        "\n",
        "  def reset_validation(self):\n",
        "    if(self.validation_complete):\n",
        "      for genre in self.classifiers:\n",
        "        self.classifiers[genre] = TrigramLaplaceSmoothing(vocab=self.training_vocab[genre],sentences=self.training_sentences[genre],alpha=1)\n",
        "      self.validation_complete = False\n",
        "\n",
        "  def validation(self,alphas=[0.001,0.005,0.01,0.25,0.5,0.8,1]):#Finds the best alpha and adds validation sentences into training model\n",
        "    if(self.validation_complete):\n",
        "      print(\"Validation has already been completed, if you would like to do it again, please call the reset_validation method prior to running validation\")\n",
        "      return\n",
        "\n",
        "    total_count = 0\n",
        "    for genre in self.classifiers:\n",
        "      total_count+=len(self.validation_sentences[genre])\n",
        "\n",
        "    #THE FOLLOWING CODE GETS ALL ALPHA COMBINATIONS GIVEN GENRE AND ALPHA LIST, the number of combinations grow exponentially with class size, but thankfully we only have 2\n",
        "    max_alpha = {}\n",
        "    combinations = [0]*len(self.classifiers)\n",
        "    for i in range(0,len(alphas)**len(self.classifiers)):\n",
        "      key = [alphas[a] for a in combinations]\n",
        "      for j in range(0,len(combinations)):\n",
        "        combinations[j]+=1\n",
        "        if(combinations[j]%len(alphas)==0 and j+1<len(combinations)):\n",
        "          combinations[j]=0\n",
        "          continue\n",
        "        break\n",
        "      max_alpha[tuple(key)] = 0\n",
        "\n",
        "    #Finds best alpha combination\n",
        "    for a in max_alpha:\n",
        "      i=0\n",
        "      for genre in self.classifiers:\n",
        "        self.classifiers[genre].set_alpha(a[i])\n",
        "        i+=1\n",
        "      correct = 0\n",
        "      for genre in self.classifiers:\n",
        "        for sentence in self.validation_sentences[genre]:\n",
        "          if(self.test_sentence(sentence,genre)):\n",
        "            correct+=1\n",
        "      max_alpha[a]=correct\n",
        "\n",
        "    #Sets best alpha for classes\n",
        "    alpha = max(max_alpha,key=max_alpha.get)\n",
        "    i=0\n",
        "    for genre in self.classifiers:\n",
        "      print(genre,alpha[i],max_alpha[alpha])\n",
        "      self.classifiers[genre].set_alpha(alpha[i])\n",
        "      i+=1\n",
        "\n",
        "    #Add validation data into classifiers\n",
        "    for genre in self.classifiers:\n",
        "      for sentence in self.validation_sentences[genre]:\n",
        "        self.classifiers[genre].add_sentence(sentence)\n",
        "    self.validation_complete = True\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzaRNwT3py0y"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTmFdy3cp7j1"
      },
      "source": [
        "Split your dataset into training, validation and testing sets - Do random sampling without replacement to create these sets, use basic python and numpy and not sklearn or other lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "468Te4MZpyVN"
      },
      "outputs": [],
      "source": [
        "#test = TrigramClassifier(corpus=brown,range=(32000,42000),trn_val_test=(0.9,0.075,0.025),alpha=1)\n",
        "test = TrigramClassifier(corpus=brown,range=(32000,42000),trn_val_test=(0.8,0.01,0.1),alpha=1)\n",
        "#test = TrigramClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-XCe1VGp8n0"
      },
      "source": [
        "Train your classifier and run predictions on the validation set per epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKLn0Sezp7T9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fcd58cb-4e3c-4bd2-cf1b-0bfb60a2a5d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fiction 0.001 711\n",
            "learned 0.005 711\n"
          ]
        }
      ],
      "source": [
        "#test.validation([0.001,0.00125,0.0015,0.00175,0.002,0.005,0.006,0.0065,0.0075,0.008,0.01,0.1,0.2,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
        "trainScore = test.evaluate('train')\n",
        "test.validation()\n",
        "valScore = test.evaluate('val')\n",
        "#test.classifiers['learned'].set_alpha(.0075)\n",
        "testScores = test.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3029QfKp_gK"
      },
      "source": [
        "Evaluate the performance of your model (accuracy, precision, recall, F1-score) -- check model performance on train and validation only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siof6PdJqDUq"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(scores):\n",
        "  for key in scores:\n",
        "    accuracy = float((scores[key][3]+scores[key][0])/(scores[key][0]+scores[key][1]+scores[key][2]+scores[key][3]))\n",
        "    print(\"'\"+key+\"' overall accuracy:{0}\".format(accuracy))\n",
        "    print(\"\\tTP:{0}\\tFN:{1}\".format(scores[key][0],scores[key][1]))\n",
        "    print(\"\\tFP:{0}\\tTN:{1}\".format(scores[key][2],scores[key][3]))\n",
        "    precision = float(scores[key][0]/(scores[key][0]+scores[key][2]))\n",
        "    recall = float(scores[key][0]/(scores[key][0]+scores[key][1]))\n",
        "    f1 = float(scores[key][0]/(scores[key][0]+0.5*(scores[key][1]+scores[key][2])))\n",
        "    print(\"Precision: {0}\".format(precision))\n",
        "    print(\"Recall: {0}\".format(recall))\n",
        "    print(\"F1-Score: {0}\".format(f1))\n",
        "    print(\"\")\n",
        "\n",
        "scores1 = {'fiction': [73, 20, 47, 110], 'learned': [110, 47, 20, 73]}\n",
        "scores2 = {'fiction': [661, 136, 426, 777], 'learned': [777, 426, 136, 661]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVZhoB7rqDmS"
      },
      "source": [
        "Stores these values in a list, to use later with matplotlib to show your train and validation curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjh4Br3IqGa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f6e85c-6be2-4184-b3c5-33aee53374ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Eval\n",
            "'learned' overall accuracy:0.909125\n",
            "\tTP:4210\tFN:727\n",
            "\tFP:0\tTN:3063\n",
            "Precision: 1.0\n",
            "Recall: 0.8527445817297954\n",
            "F1-Score: 0.9205203891986443\n",
            "\n",
            "'fiction' overall accuracy:0.909125\n",
            "\tTP:3063\tFN:0\n",
            "\tFP:727\tTN:4210\n",
            "Precision: 0.808179419525066\n",
            "Recall: 1.0\n",
            "F1-Score: 0.8939150736903546\n",
            "\n",
            "Val Eval\n",
            "'learned' overall accuracy:0.978\n",
            "\tTP:5450\tFN:81\n",
            "\tFP:117\tTN:3352\n",
            "Precision: 0.9789832944135082\n",
            "Recall: 0.9853552702947026\n",
            "F1-Score: 0.9821589475581186\n",
            "\n",
            "'fiction' overall accuracy:0.978\n",
            "\tTP:3352\tFN:117\n",
            "\tFP:81\tTN:5450\n",
            "Precision: 0.9764054762598311\n",
            "Recall: 0.9662727010665898\n",
            "F1-Score: 0.971312662996233\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Eval\")\n",
        "confusion_matrix(trainScore)\n",
        "print(\"Val Eval\")\n",
        "confusion_matrix(valScore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwvNh_BSqG52"
      },
      "source": [
        "Evaluate performance on test set only Once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOCVF5g8qI5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bd8507-8fdd-4253-a740-5c6c2ec3f3d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Eval\n",
            "'learned' overall accuracy:0.711\n",
            "\tTP:389\tFN:216\n",
            "\tFP:73\tTN:322\n",
            "Precision: 0.841991341991342\n",
            "Recall: 0.6429752066115703\n",
            "F1-Score: 0.7291471415182755\n",
            "\n",
            "'fiction' overall accuracy:0.711\n",
            "\tTP:322\tFN:73\n",
            "\tFP:216\tTN:389\n",
            "Precision: 0.5985130111524164\n",
            "Recall: 0.8151898734177215\n",
            "F1-Score: 0.6902465166130761\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Eval\")\n",
        "confusion_matrix(testScores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}